[MODEL INFO]:
________________________________________________________________________________________________________________________
Model Name: model
________________________________________________________________________________________________________________________
ID          Name                    Type                    Device      Notes                                           
========================================================================================================================
0/251       input_1                 InputLayer              INPUT                                                       
------------------------------------------------------------------------------------------------------------------------
1/251       conv2d                  Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
2/251       batch_normalization     BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
3/251       leaky_re_lu             LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
4/251       zero_padding2d          ZeroPadding2D           DPU                                                         
------------------------------------------------------------------------------------------------------------------------
5/251       conv2d_1                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
6/251       batch_normalization_1   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
7/251       leaky_re_lu_1           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
8/251       conv2d_2                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
9/251       batch_normalization_2   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
10/251      leaky_re_lu_2           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
11/251      conv2d_3                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
12/251      batch_normalization_3   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
13/251      leaky_re_lu_3           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
14/251      add                     Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
15/251      zero_padding2d_1        ZeroPadding2D           DPU                                                         
------------------------------------------------------------------------------------------------------------------------
16/251      conv2d_4                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
17/251      batch_normalization_4   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
18/251      leaky_re_lu_4           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
19/251      conv2d_5                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
20/251      batch_normalization_5   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
21/251      leaky_re_lu_5           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
22/251      conv2d_6                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
23/251      batch_normalization_6   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
24/251      leaky_re_lu_6           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
25/251      add_1                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
26/251      conv2d_7                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
27/251      batch_normalization_7   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
28/251      leaky_re_lu_7           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
29/251      conv2d_8                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
30/251      batch_normalization_8   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
31/251      leaky_re_lu_8           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
32/251      add_2                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
33/251      zero_padding2d_2        ZeroPadding2D           DPU                                                         
------------------------------------------------------------------------------------------------------------------------
34/251      conv2d_9                Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
35/251      batch_normalization_9   BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
36/251      leaky_re_lu_9           LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
37/251      conv2d_10               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
38/251      batch_normalization_10  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
39/251      leaky_re_lu_10          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
40/251      conv2d_11               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
41/251      batch_normalization_11  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
42/251      leaky_re_lu_11          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
43/251      add_3                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
44/251      conv2d_12               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
45/251      batch_normalization_12  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
46/251      leaky_re_lu_12          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
47/251      conv2d_13               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
48/251      batch_normalization_13  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
49/251      leaky_re_lu_13          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
50/251      add_4                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
51/251      conv2d_14               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
52/251      batch_normalization_14  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
53/251      leaky_re_lu_14          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
54/251      conv2d_15               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
55/251      batch_normalization_15  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
56/251      leaky_re_lu_15          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
57/251      add_5                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
58/251      conv2d_16               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
59/251      batch_normalization_16  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
60/251      leaky_re_lu_16          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
61/251      conv2d_17               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
62/251      batch_normalization_17  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
63/251      leaky_re_lu_17          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
64/251      add_6                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
65/251      conv2d_18               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
66/251      batch_normalization_18  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
67/251      leaky_re_lu_18          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
68/251      conv2d_19               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
69/251      batch_normalization_19  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
70/251      leaky_re_lu_19          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
71/251      add_7                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
72/251      conv2d_20               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
73/251      batch_normalization_20  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
74/251      leaky_re_lu_20          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
75/251      conv2d_21               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
76/251      batch_normalization_21  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
77/251      leaky_re_lu_21          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
78/251      add_8                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
79/251      conv2d_22               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
80/251      batch_normalization_22  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
81/251      leaky_re_lu_22          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
82/251      conv2d_23               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
83/251      batch_normalization_23  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
84/251      leaky_re_lu_23          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
85/251      add_9                   Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
86/251      conv2d_24               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
87/251      batch_normalization_24  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
88/251      leaky_re_lu_24          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
89/251      conv2d_25               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
90/251      batch_normalization_25  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
91/251      leaky_re_lu_25          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
92/251      add_10                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
93/251      zero_padding2d_3        ZeroPadding2D           DPU                                                         
------------------------------------------------------------------------------------------------------------------------
94/251      conv2d_26               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
95/251      batch_normalization_26  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
96/251      leaky_re_lu_26          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
97/251      conv2d_27               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
98/251      batch_normalization_27  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
99/251      leaky_re_lu_27          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
100/251     conv2d_28               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
101/251     batch_normalization_28  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
102/251     leaky_re_lu_28          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
103/251     add_11                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
104/251     conv2d_29               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
105/251     batch_normalization_29  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
106/251     leaky_re_lu_29          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
107/251     conv2d_30               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
108/251     batch_normalization_30  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
109/251     leaky_re_lu_30          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
110/251     add_12                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
111/251     conv2d_31               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
112/251     batch_normalization_31  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
113/251     leaky_re_lu_31          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
114/251     conv2d_32               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
115/251     batch_normalization_32  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
116/251     leaky_re_lu_32          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
117/251     add_13                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
118/251     conv2d_33               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
119/251     batch_normalization_33  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
120/251     leaky_re_lu_33          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
121/251     conv2d_34               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
122/251     batch_normalization_34  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
123/251     leaky_re_lu_34          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
124/251     add_14                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
125/251     conv2d_35               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
126/251     batch_normalization_35  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
127/251     leaky_re_lu_35          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
128/251     conv2d_36               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
129/251     batch_normalization_36  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
130/251     leaky_re_lu_36          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
131/251     add_15                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
132/251     conv2d_37               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
133/251     batch_normalization_37  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
134/251     leaky_re_lu_37          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
135/251     conv2d_38               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
136/251     batch_normalization_38  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
137/251     leaky_re_lu_38          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
138/251     add_16                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
139/251     conv2d_39               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
140/251     batch_normalization_39  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
141/251     leaky_re_lu_39          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
142/251     conv2d_40               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
143/251     batch_normalization_40  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
144/251     leaky_re_lu_40          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
145/251     add_17                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
146/251     conv2d_41               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
147/251     batch_normalization_41  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
148/251     leaky_re_lu_41          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
149/251     conv2d_42               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
150/251     batch_normalization_42  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
151/251     leaky_re_lu_42          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
152/251     add_18                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
153/251     zero_padding2d_4        ZeroPadding2D           DPU                                                         
------------------------------------------------------------------------------------------------------------------------
154/251     conv2d_43               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
155/251     batch_normalization_43  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
156/251     leaky_re_lu_43          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
157/251     conv2d_44               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
158/251     batch_normalization_44  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
159/251     leaky_re_lu_44          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
160/251     conv2d_45               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
161/251     batch_normalization_45  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
162/251     leaky_re_lu_45          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
163/251     add_19                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
164/251     conv2d_46               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
165/251     batch_normalization_46  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
166/251     leaky_re_lu_46          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
167/251     conv2d_47               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
168/251     batch_normalization_47  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
169/251     leaky_re_lu_47          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
170/251     add_20                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
171/251     conv2d_48               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
172/251     batch_normalization_48  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
173/251     leaky_re_lu_48          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
174/251     conv2d_49               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
175/251     batch_normalization_49  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
176/251     leaky_re_lu_49          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
177/251     add_21                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
178/251     conv2d_50               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
179/251     batch_normalization_50  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
180/251     leaky_re_lu_50          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
181/251     conv2d_51               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
182/251     batch_normalization_51  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
183/251     leaky_re_lu_51          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
184/251     add_22                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
185/251     conv2d_52               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
186/251     batch_normalization_52  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
187/251     leaky_re_lu_52          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
188/251     conv2d_53               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
189/251     batch_normalization_53  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
190/251     leaky_re_lu_53          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
191/251     conv2d_54               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
192/251     batch_normalization_54  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
193/251     leaky_re_lu_54          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
194/251     conv2d_55               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
195/251     batch_normalization_55  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
196/251     leaky_re_lu_55          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
197/251     conv2d_56               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
198/251     batch_normalization_56  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
199/251     leaky_re_lu_56          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
200/251     conv2d_59               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
201/251     batch_normalization_58  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
202/251     leaky_re_lu_58          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
203/251     up_sampling2d           UpSampling2D            DPU                                                         
------------------------------------------------------------------------------------------------------------------------
204/251     concatenate             Concatenate             DPU                                                         
------------------------------------------------------------------------------------------------------------------------
205/251     conv2d_60               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
206/251     batch_normalization_59  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
207/251     leaky_re_lu_59          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
208/251     conv2d_61               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
209/251     batch_normalization_60  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
210/251     leaky_re_lu_60          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
211/251     conv2d_62               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
212/251     batch_normalization_61  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
213/251     leaky_re_lu_61          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
214/251     conv2d_63               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
215/251     batch_normalization_62  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
216/251     leaky_re_lu_62          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
217/251     conv2d_64               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
218/251     batch_normalization_63  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
219/251     leaky_re_lu_63          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
220/251     conv2d_67               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
221/251     batch_normalization_65  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
222/251     leaky_re_lu_65          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
223/251     up_sampling2d_1         UpSampling2D            DPU                                                         
------------------------------------------------------------------------------------------------------------------------
224/251     concatenate_1           Concatenate             DPU                                                         
------------------------------------------------------------------------------------------------------------------------
225/251     conv2d_68               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
226/251     batch_normalization_66  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
227/251     leaky_re_lu_66          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
228/251     conv2d_69               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
229/251     batch_normalization_67  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
230/251     leaky_re_lu_67          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
231/251     conv2d_70               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
232/251     batch_normalization_68  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
233/251     leaky_re_lu_68          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
234/251     conv2d_71               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
235/251     batch_normalization_69  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
236/251     leaky_re_lu_69          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
237/251     conv2d_72               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
238/251     batch_normalization_70  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
239/251     leaky_re_lu_70          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
240/251     conv2d_57               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
241/251     conv2d_65               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
242/251     conv2d_73               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
243/251     batch_normalization_57  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
244/251     batch_normalization_64  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
245/251     batch_normalization_71  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
246/251     leaky_re_lu_57          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
247/251     leaky_re_lu_64          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
248/251     leaky_re_lu_71          LeakyReLU               DPU                                                         
------------------------------------------------------------------------------------------------------------------------
249/251     conv2d_58               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
250/251     conv2d_66               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
251/251     conv2d_74               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
========================================================================================================================
[SUMMARY INFO]:
- [Target Name]: DPUCZDX8G_ISA1_B3136
- [Target Type]: DPUCZDX8G
- [Total Layers]: 252
- [Layer Types]: InputLayer(1) Conv2D<linear>(75) BatchNormalization(72) LeakyReLU(72) ZeroPadding2D(5) Add(23) UpSampling2D(2) Concatenate(2) 
- [Partition Results]: INPUT(1) DPU(251) 

  All layers are supported and successfully mapped to DPU.
========================================================================================================================
[NOTES INFO]:

  All layers are supported and successfully mapped to DPU.
========================================================================================================================

Detailed Model Info: 

Layer ID: 0
Layer Name: input_1
Layer Type: InputLayer
Device: INPUT
Notes: 
    None
Layer Config:
{'batch_input_shape': (None, 416, 416, 3),
 'dtype': 'float32',
 'name': 'input_1',
 'ragged': False,
 'sparse': False}
________________________________________________________________________________________________________________________
Layer ID: 1
Layer Name: conv2d
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 32,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 2
Layer Name: batch_normalization
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 3
Layer Name: leaky_re_lu
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 4
Layer Name: zero_padding2d
Layer Type: ZeroPadding2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'zero_padding2d',
 'padding': ((1, 0), (1, 0)),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 5
Layer Name: conv2d_1
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_1',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 6
Layer Name: batch_normalization_1
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_1.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_1',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 7
Layer Name: leaky_re_lu_1
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_1',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 8
Layer Name: conv2d_2
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 32,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_2',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 9
Layer Name: batch_normalization_2
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_2.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_2',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 10
Layer Name: leaky_re_lu_2
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_2',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 11
Layer Name: conv2d_3
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_3',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 12
Layer Name: batch_normalization_3
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_3.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_3',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 13
Layer Name: leaky_re_lu_3
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_3',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 14
Layer Name: add
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 15
Layer Name: zero_padding2d_1
Layer Type: ZeroPadding2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'zero_padding2d_1',
 'padding': ((1, 0), (1, 0)),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 16
Layer Name: conv2d_4
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_4',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 17
Layer Name: batch_normalization_4
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_4.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_4',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 18
Layer Name: leaky_re_lu_4
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_4',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 19
Layer Name: conv2d_5
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_5',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 20
Layer Name: batch_normalization_5
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_5.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_5',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 21
Layer Name: leaky_re_lu_5
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_5',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 22
Layer Name: conv2d_6
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_6',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 23
Layer Name: batch_normalization_6
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_6.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_6',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 24
Layer Name: leaky_re_lu_6
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_6',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 25
Layer Name: add_1
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_1', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 26
Layer Name: conv2d_7
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_7',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 27
Layer Name: batch_normalization_7
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_7.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_7',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 28
Layer Name: leaky_re_lu_7
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_7',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 29
Layer Name: conv2d_8
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_8',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 30
Layer Name: batch_normalization_8
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_8.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_8',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 31
Layer Name: leaky_re_lu_8
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_8',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 32
Layer Name: add_2
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_2', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 33
Layer Name: zero_padding2d_2
Layer Type: ZeroPadding2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'zero_padding2d_2',
 'padding': ((1, 0), (1, 0)),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 34
Layer Name: conv2d_9
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_9',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 35
Layer Name: batch_normalization_9
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_9.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_9',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 36
Layer Name: leaky_re_lu_9
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_9',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 37
Layer Name: conv2d_10
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_10',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 38
Layer Name: batch_normalization_10
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_10.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_10',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 39
Layer Name: leaky_re_lu_10
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_10',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 40
Layer Name: conv2d_11
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_11',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 41
Layer Name: batch_normalization_11
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_11.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_11',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 42
Layer Name: leaky_re_lu_11
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_11',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 43
Layer Name: add_3
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_3', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 44
Layer Name: conv2d_12
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_12',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 45
Layer Name: batch_normalization_12
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_12.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_12',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 46
Layer Name: leaky_re_lu_12
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_12',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 47
Layer Name: conv2d_13
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_13',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 48
Layer Name: batch_normalization_13
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_13.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_13',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 49
Layer Name: leaky_re_lu_13
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_13',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 50
Layer Name: add_4
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_4', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 51
Layer Name: conv2d_14
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_14',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 52
Layer Name: batch_normalization_14
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_14.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_14',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 53
Layer Name: leaky_re_lu_14
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_14',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 54
Layer Name: conv2d_15
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_15',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 55
Layer Name: batch_normalization_15
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_15.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_15',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 56
Layer Name: leaky_re_lu_15
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_15',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 57
Layer Name: add_5
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_5', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 58
Layer Name: conv2d_16
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_16',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 59
Layer Name: batch_normalization_16
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_16.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_16',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 60
Layer Name: leaky_re_lu_16
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_16',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 61
Layer Name: conv2d_17
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_17',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 62
Layer Name: batch_normalization_17
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_17.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_17',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 63
Layer Name: leaky_re_lu_17
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_17',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 64
Layer Name: add_6
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_6', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 65
Layer Name: conv2d_18
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_18',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 66
Layer Name: batch_normalization_18
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_18.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_18',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 67
Layer Name: leaky_re_lu_18
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_18',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 68
Layer Name: conv2d_19
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_19',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 69
Layer Name: batch_normalization_19
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_19.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_19',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 70
Layer Name: leaky_re_lu_19
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_19',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 71
Layer Name: add_7
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_7', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 72
Layer Name: conv2d_20
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_20',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 73
Layer Name: batch_normalization_20
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_20.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_20',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 74
Layer Name: leaky_re_lu_20
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_20',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 75
Layer Name: conv2d_21
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_21',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 76
Layer Name: batch_normalization_21
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_21.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_21',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 77
Layer Name: leaky_re_lu_21
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_21',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 78
Layer Name: add_8
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_8', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 79
Layer Name: conv2d_22
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_22',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 80
Layer Name: batch_normalization_22
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_22.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_22',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 81
Layer Name: leaky_re_lu_22
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_22',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 82
Layer Name: conv2d_23
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_23',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 83
Layer Name: batch_normalization_23
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_23.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_23',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 84
Layer Name: leaky_re_lu_23
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_23',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 85
Layer Name: add_9
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_9', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 86
Layer Name: conv2d_24
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_24',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 87
Layer Name: batch_normalization_24
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_24.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_24',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 88
Layer Name: leaky_re_lu_24
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_24',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 89
Layer Name: conv2d_25
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_25',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 90
Layer Name: batch_normalization_25
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_25.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_25',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 91
Layer Name: leaky_re_lu_25
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_25',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 92
Layer Name: add_10
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_10', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 93
Layer Name: zero_padding2d_3
Layer Type: ZeroPadding2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'zero_padding2d_3',
 'padding': ((1, 0), (1, 0)),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 94
Layer Name: conv2d_26
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_26',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 95
Layer Name: batch_normalization_26
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_26.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_26',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 96
Layer Name: leaky_re_lu_26
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_26',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 97
Layer Name: conv2d_27
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_27',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 98
Layer Name: batch_normalization_27
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_27.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_27',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 99
Layer Name: leaky_re_lu_27
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_27',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 100
Layer Name: conv2d_28
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_28',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 101
Layer Name: batch_normalization_28
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_28.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_28',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 102
Layer Name: leaky_re_lu_28
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_28',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 103
Layer Name: add_11
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_11', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 104
Layer Name: conv2d_29
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_29',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 105
Layer Name: batch_normalization_29
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_29.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_29',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 106
Layer Name: leaky_re_lu_29
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_29',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 107
Layer Name: conv2d_30
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_30',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 108
Layer Name: batch_normalization_30
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_30.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_30',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 109
Layer Name: leaky_re_lu_30
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_30',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 110
Layer Name: add_12
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_12', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 111
Layer Name: conv2d_31
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_31',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 112
Layer Name: batch_normalization_31
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_31.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_31',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 113
Layer Name: leaky_re_lu_31
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_31',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 114
Layer Name: conv2d_32
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_32',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 115
Layer Name: batch_normalization_32
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_32.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_32',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 116
Layer Name: leaky_re_lu_32
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_32',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 117
Layer Name: add_13
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_13', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 118
Layer Name: conv2d_33
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_33',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 119
Layer Name: batch_normalization_33
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_33.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_33',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 120
Layer Name: leaky_re_lu_33
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_33',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 121
Layer Name: conv2d_34
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_34',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 122
Layer Name: batch_normalization_34
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_34.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_34',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 123
Layer Name: leaky_re_lu_34
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_34',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 124
Layer Name: add_14
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_14', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 125
Layer Name: conv2d_35
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_35',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 126
Layer Name: batch_normalization_35
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_35.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_35',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 127
Layer Name: leaky_re_lu_35
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_35',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 128
Layer Name: conv2d_36
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_36',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 129
Layer Name: batch_normalization_36
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_36.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_36',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 130
Layer Name: leaky_re_lu_36
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_36',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 131
Layer Name: add_15
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_15', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 132
Layer Name: conv2d_37
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_37',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 133
Layer Name: batch_normalization_37
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_37.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_37',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 134
Layer Name: leaky_re_lu_37
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_37',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 135
Layer Name: conv2d_38
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_38',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 136
Layer Name: batch_normalization_38
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_38.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_38',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 137
Layer Name: leaky_re_lu_38
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_38',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 138
Layer Name: add_16
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_16', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 139
Layer Name: conv2d_39
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_39',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 140
Layer Name: batch_normalization_39
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_39.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_39',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 141
Layer Name: leaky_re_lu_39
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_39',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 142
Layer Name: conv2d_40
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_40',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 143
Layer Name: batch_normalization_40
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_40.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_40',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 144
Layer Name: leaky_re_lu_40
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_40',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 145
Layer Name: add_17
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_17', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 146
Layer Name: conv2d_41
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_41',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 147
Layer Name: batch_normalization_41
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_41.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_41',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 148
Layer Name: leaky_re_lu_41
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_41',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 149
Layer Name: conv2d_42
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_42',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 150
Layer Name: batch_normalization_42
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_42.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_42',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 151
Layer Name: leaky_re_lu_42
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_42',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 152
Layer Name: add_18
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_18', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 153
Layer Name: zero_padding2d_4
Layer Type: ZeroPadding2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'zero_padding2d_4',
 'padding': ((1, 0), (1, 0)),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 154
Layer Name: conv2d_43
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_43',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 155
Layer Name: batch_normalization_43
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_43.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_43',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 156
Layer Name: leaky_re_lu_43
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_43',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 157
Layer Name: conv2d_44
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_44',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 158
Layer Name: batch_normalization_44
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_44.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_44',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 159
Layer Name: leaky_re_lu_44
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_44',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 160
Layer Name: conv2d_45
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_45',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 161
Layer Name: batch_normalization_45
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_45.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_45',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 162
Layer Name: leaky_re_lu_45
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_45',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 163
Layer Name: add_19
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_19', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 164
Layer Name: conv2d_46
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_46',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 165
Layer Name: batch_normalization_46
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_46.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_46',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 166
Layer Name: leaky_re_lu_46
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_46',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 167
Layer Name: conv2d_47
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_47',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 168
Layer Name: batch_normalization_47
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_47.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_47',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 169
Layer Name: leaky_re_lu_47
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_47',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 170
Layer Name: add_20
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_20', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 171
Layer Name: conv2d_48
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_48',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 172
Layer Name: batch_normalization_48
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_48.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_48',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 173
Layer Name: leaky_re_lu_48
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_48',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 174
Layer Name: conv2d_49
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_49',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 175
Layer Name: batch_normalization_49
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_49.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_49',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 176
Layer Name: leaky_re_lu_49
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_49',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 177
Layer Name: add_21
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_21', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 178
Layer Name: conv2d_50
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_50',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 179
Layer Name: batch_normalization_50
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_50.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_50',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 180
Layer Name: leaky_re_lu_50
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_50',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 181
Layer Name: conv2d_51
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_51',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 182
Layer Name: batch_normalization_51
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_51.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_51',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 183
Layer Name: leaky_re_lu_51
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_51',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 184
Layer Name: add_22
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_22', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 185
Layer Name: conv2d_52
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_52',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 186
Layer Name: batch_normalization_52
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_52.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_52',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 187
Layer Name: leaky_re_lu_52
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_52',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 188
Layer Name: conv2d_53
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_53',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 189
Layer Name: batch_normalization_53
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_53.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_53',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 190
Layer Name: leaky_re_lu_53
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_53',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 191
Layer Name: conv2d_54
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_54',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 192
Layer Name: batch_normalization_54
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_54.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_54',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 193
Layer Name: leaky_re_lu_54
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_54',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 194
Layer Name: conv2d_55
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_55',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 195
Layer Name: batch_normalization_55
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_55.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_55',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 196
Layer Name: leaky_re_lu_55
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_55',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 197
Layer Name: conv2d_56
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_56',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 198
Layer Name: batch_normalization_56
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_56.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_56',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 199
Layer Name: leaky_re_lu_56
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_56',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 200
Layer Name: conv2d_59
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_59',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 201
Layer Name: batch_normalization_58
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_59.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_58',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 202
Layer Name: leaky_re_lu_58
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_58',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 203
Layer Name: up_sampling2d
Layer Type: UpSampling2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'interpolation': 'nearest',
 'name': 'up_sampling2d',
 'size': (2, 2),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 204
Layer Name: concatenate
Layer Type: Concatenate
Device: DPU
Notes: 
    None
Layer Config:
{'axis': -1, 'dtype': 'float32', 'name': 'concatenate', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 205
Layer Name: conv2d_60
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_60',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 206
Layer Name: batch_normalization_59
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_60.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_59',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 207
Layer Name: leaky_re_lu_59
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_59',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 208
Layer Name: conv2d_61
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_61',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 209
Layer Name: batch_normalization_60
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_61.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_60',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 210
Layer Name: leaky_re_lu_60
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_60',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 211
Layer Name: conv2d_62
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_62',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 212
Layer Name: batch_normalization_61
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_62.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_61',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 213
Layer Name: leaky_re_lu_61
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_61',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 214
Layer Name: conv2d_63
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_63',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 215
Layer Name: batch_normalization_62
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_63.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_62',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 216
Layer Name: leaky_re_lu_62
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_62',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 217
Layer Name: conv2d_64
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_64',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 218
Layer Name: batch_normalization_63
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_64.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_63',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 219
Layer Name: leaky_re_lu_63
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_63',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 220
Layer Name: conv2d_67
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_67',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 221
Layer Name: batch_normalization_65
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_67.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_65',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 222
Layer Name: leaky_re_lu_65
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_65',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 223
Layer Name: up_sampling2d_1
Layer Type: UpSampling2D
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'interpolation': 'nearest',
 'name': 'up_sampling2d_1',
 'size': (2, 2),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 224
Layer Name: concatenate_1
Layer Type: Concatenate
Device: DPU
Notes: 
    None
Layer Config:
{'axis': -1, 'dtype': 'float32', 'name': 'concatenate_1', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 225
Layer Name: conv2d_68
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_68',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 226
Layer Name: batch_normalization_66
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_68.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_66',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 227
Layer Name: leaky_re_lu_66
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_66',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 228
Layer Name: conv2d_69
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_69',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 229
Layer Name: batch_normalization_67
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_69.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_67',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 230
Layer Name: leaky_re_lu_67
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_67',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 231
Layer Name: conv2d_70
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_70',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 232
Layer Name: batch_normalization_68
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_70.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_68',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 233
Layer Name: leaky_re_lu_68
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_68',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 234
Layer Name: conv2d_71
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_71',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 235
Layer Name: batch_normalization_69
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_71.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_69',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 236
Layer Name: leaky_re_lu_69
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_69',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 237
Layer Name: conv2d_72
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_72',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 238
Layer Name: batch_normalization_70
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_72.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_70',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 239
Layer Name: leaky_re_lu_70
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_70',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 240
Layer Name: conv2d_57
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 1024,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_57',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 241
Layer Name: conv2d_65
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_65',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 242
Layer Name: conv2d_73
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (3, 3),
 'name': 'conv2d_73',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': False}
________________________________________________________________________________________________________________________
Layer ID: 243
Layer Name: batch_normalization_57
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_57.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_57',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 244
Layer Name: batch_normalization_64
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_65.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_64',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 245
Layer Name: batch_normalization_71
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_73.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_71',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 246
Layer Name: leaky_re_lu_57
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_57',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 247
Layer Name: leaky_re_lu_64
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_64',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 248
Layer Name: leaky_re_lu_71
Layer Type: LeakyReLU
Device: DPU
Notes: 
    1. Converted alpha 0.1 to 26./256. to match DPU implementation.
Layer Config:
{'alpha': 0.10000000149011612,
 'dtype': 'float32',
 'name': 'leaky_re_lu_71',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 249
Layer Name: conv2d_58
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 255,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_58',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 250
Layer Name: conv2d_66
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 255,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_66',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 251
Layer Name: conv2d_74
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 255,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': {'class_name': 'L2',
                        'config': {'l2': 0.0005000000237487257}},
 'kernel_size': (1, 1),
 'name': 'conv2d_74',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________